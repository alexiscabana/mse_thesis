{
\setlength{\parindent}{2em}
\chapter{State of the Art}\label{cha:state-of-the-art}
Saving the state of a running application to a file has been a very well-known challenge in the world of computer science, one that has its roots back to when the computers became powerful enough to run complicated programs. With the rise of local networks and the Ethernet protocol in the 1970s, an increasing amount of processing units could be linked together through a local network in order to improve the execution speed of difficult computation \cite{book:andrews}. This gave rise to the field of distributed computing, where scalability, parallelization of algorithms and efficient inter-node communication are among the very active topics of research.

Of course, the more complicated a system is, the more failure-prone it becomes. This is why it's imperative for designers of parallel algorithms to be careful when programming their application. It has to be made in such a way that it stays tolerant to eventual faults in the computing nodes of the network. For instance, one can think of the algorithms involved in numerical weather prediction software, that theoretically never finish as long as updated data is fed into the system. It is important for the forecasting industry not to loose any of the results that were previously solved if an unfortunate event occurs. \textit{Fault-tolerant computing} is the research field that finds solutions to this problem in multiple ways. In the context of distributed computing, one of the ways to mitigate the problem is to use a checkpoint and restart mechanism.

This technique allows the program to save itself while it's running, and to restart at a previous checkpoint. A "save" can take many forms, and its content is ultimately decided by the developers of the program. Before a final design is produced, some questions need to be answered:
\begin{enumerate}
	\item \textbf{What needs to be saved?} There needs to be a clear understanding of the program and how it works. Is saving only the intermediate result of a computation considered a sufficient condition to be able to restore the program back to where it was? Is saving the entire state of the operating system required? Of the entire computer? 
	\item \textbf{In which format should the data be saved?} This can be binary data, numerical data, text, etc. This is again highly dependent on the application. A suitable file format has to be used depending on the data to store.
	\item \textbf{How is the data saved?} How can a checkpoint take form? This depends on the content. Most of the time, this will be a file written to non-volatile memory. Again, the file format has a role to play.
	\item \textbf{How often is saving necessary?} A checkpoint can take a lot of space, and that amount usually grows linearly with the number of execution threads. In huge systems, this is not a trivial question. In addition, not only does a checkpoint take up hard disk space, it also induces an overhead in the execution of the program. Depending on the desired granularity, saving the relevant data can take a significant amount of time. This is represented by $O_F$ in \autoref{fig:chkpt-scheme}. This factor is important, especially in big distributed systems where computing time is expensive. As an example, the Titan supercomputer in the United States racks up \$9 million USD in electricity bills yearly \cite{online:henn}.
	\item \textbf{How long does it take to restart?} Saving at checkpoints takes time, but so does recovery. \autoref{fig:chkpt-scheme} shows this with $R_F$. Another point to consider is how often the system needs to restart back. In the end, restarting to a past state must be as straightforward as possible.
\end{enumerate}
\begin{figure}[H]
	\centering
	\includesvg[width=0.9\linewidth]{svg/chkpt-copy}
	\caption{Checkpoint/restart as a stochastic renewal reward process.\cite{misc:chkpt-scheme}}
	\label{fig:chkpt-scheme}
\end{figure}

\subsection*{Checkpointing Schemes}
There are different checkpointing schemes that are adapted to different needs. On one hand, it is possible to checkpoint the application at predetermined intervals $\Delta t$ (i.e every minute). This is useful when applicable, because it puts an upper bound on the amount of data/time loss in a worst case scenario. However, this mitigation method is not always possible for every type of computation. 

The second approach is to do it sporadically. This can be used when it's impossible to predict the amount of time required for a given computation. Unfortunately, it also means that the user doesn't know exactly when checkpoints will occur nor can she/he upper-bound the maximum amount of data/time loss.

\subsection*{Applicability to BBPSim}
Why exactly can these concepts be useful in the case of a simulator like BBPSim? The checkpoint and restart technique is not only applicable to the distributed computing, it can be adapted to fit the needs of multiple kinds of programs. At the very least, some of the concepts can serve as inspiration to design a save \& restore feature. In the following sections, some existing \textit{snapshotting} solutions in released software will be investigated. Using available source code and documentation, it will be possible to see that a checkpoint/restart feature can be implemented at different levels. In the end, the analysis will extract a set of working ideas as inspiration for the save \& restore in BBPSim.

%---state of the art analysis
\input{tex/sota-virtualbox}
\input{tex/sota-criu}
\input{tex/sota-c3}

}